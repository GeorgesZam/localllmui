name: Build Local Chat

on:
  push:
    branches: [main, master]
  workflow_dispatch:

jobs:
  build-windows:
    runs-on: windows-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      # Cache Tesseract et Poppler
      - name: Cache Chocolatey packages
        uses: actions/cache@v4
        id: cache-choco
        with:
          path: |
            C:\Program Files\Tesseract-OCR
            C:\ProgramData\chocolatey\lib\poppler
          key: choco-tesseract-poppler-v2
      
      - name: Install Tesseract OCR
        if: steps.cache-choco.outputs.cache-hit != 'true'
        run: choco install tesseract --no-progress
        shell: pwsh
      
      - name: Add Tesseract to PATH
        run: echo "C:\Program Files\Tesseract-OCR" | Out-File -FilePath $env:GITHUB_PATH -Encoding utf8 -Append
        shell: pwsh
      
      - name: Install Poppler
        if: steps.cache-choco.outputs.cache-hit != 'true'
        run: choco install poppler --no-progress
        shell: pwsh
      
      # Cache le mod√®le LLM
      - name: Cache LLM model
        uses: actions/cache@v4
        id: cache-model
        with:
          path: models/model.gguf
          key: qwen-2.5-0.5b-q4km-v2
      
      - name: Download LLM model
        if: steps.cache-model.outputs.cache-hit != 'true'
        run: |
          mkdir -p models
          curl -L -o models/model.gguf https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct-GGUF/resolve/main/qwen2.5-0.5b-instruct-q4_k_m.gguf
        shell: bash
      
      # Cache pip
      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~\AppData\Local\pip\Cache
          key: pip-${{ runner.os }}-py311-v2
      
      # Install dependencies
      - name: Install dependencies
        run: |
          pip install --upgrade pip wheel
          pip install pyinstaller==6.3.0
          pip install llama-cpp-python --prefer-binary --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cpu
          pip install customtkinter==5.2.1 sentence-transformers==2.2.2
          pip install numpy PyPDF2 openpyxl python-pptx python-docx
          pip install pytesseract pdf2image Pillow
        shell: bash
      
      # Cache embedding model
      - name: Cache embedding model
        uses: actions/cache@v4
        id: cache-embedding
        with:
          path: embedding_model
          key: bge-small-en-v1.5-v2
      
      - name: Pre-download embedding model
        if: steps.cache-embedding.outputs.cache-hit != 'true'
        run: |
          python -c "from sentence_transformers import SentenceTransformer; m = SentenceTransformer('BAAI/bge-small-en-v1.5'); m.save('embedding_model')"
        shell: bash
      
      - name: Create data folder
        run: mkdir -p data
        shell: bash
      
      - name: Build executable
        run: |
          $llamaPath = python -c "import llama_cpp; import os; print(os.path.dirname(llama_cpp.__file__))"
          $stPath = python -c "import sentence_transformers; import os; print(os.path.dirname(sentence_transformers.__file__))"
          $ctkPath = python -c "import customtkinter; import os; print(os.path.dirname(customtkinter.__file__))"
          
          cd src
          pyinstaller --onefile --windowed --name "LocalChat" `
            --add-data "../models;models" `
            --add-data "../data;data" `
            --add-data "../embedding_model;embedding_model" `
            --add-data "$llamaPath;llama_cpp" `
            --add-data "$stPath;sentence_transformers" `
            --add-data "$ctkPath;customtkinter" `
            --collect-all llama_cpp `
            --collect-all sentence_transformers `
            --collect-all customtkinter `
            --collect-submodules transformers.models `
            --collect-submodules tokenizers `
            --hidden-import llama_cpp `
            --hidden-import sentence_transformers `
            --hidden-import customtkinter `
            --hidden-import PyPDF2 `
            --hidden-import openpyxl `
            --hidden-import pptx `
            --hidden-import docx `
            --hidden-import pytesseract `
            --hidden-import pdf2image `
            --hidden-import PIL `
            --exclude-module matplotlib `
            --exclude-module scipy `
            --exclude-module pandas `
            --exclude-module notebook `
            --exclude-module pytest `
            --strip `
            --noupx `
            main.py
        shell: pwsh
      
      - uses: actions/upload-artifact@v4
        with:
          name: LocalChat-Windows
          path: src/dist/*.exe
          compression-level: 9
