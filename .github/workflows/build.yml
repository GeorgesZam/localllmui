name: Build Local Chat

on:
  push:
    branches: [main, master]
  workflow_dispatch:

jobs:
  build:
    runs-on: windows-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install deps
        run: |
          pip install pyinstaller
          pip install llama-cpp-python --prefer-binary
          pip install sentence-transformers
          pip install numpy
      
      - name: Download model
        run: |
          mkdir models
          curl -L -o models/model.gguf https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/qwen2.5-1.5b-instruct-q4_k_m.gguf
        shell: bash
      
      - name: Create data folder
        run: mkdir data
      
      - name: Find paths and build
        run: |
          $llamaPath = python -c "import llama_cpp; import os; print(os.path.dirname(llama_cpp.__file__))"
          cd src
          pyinstaller --onefile --windowed --name "LocalChat" --add-data "../models;models" --add-data "../data;data" --add-data "$llamaPath;llama_cpp" --hidden-import llama_cpp --hidden-import sentence_transformers --collect-all sentence_transformers main.py
        shell: pwsh
      
      - uses: actions/upload-artifact@v4
        with:
          name: LocalChat-Windows
          path: src/dist/*.exe
