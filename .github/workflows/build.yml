name: Build Local Chat

on:
  push:
    branches: [main, master]
  workflow_dispatch:

jobs:
  build:
    runs-on: windows-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install deps
        run: |
          pip install pyinstaller
          pip install llama-cpp-python --prefer-binary
      
      - name: Download model
        run: |
          mkdir models
          curl -L -o models/model.gguf https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/qwen2.5-1.5b-instruct-q4_k_m.gguf
        shell: bash
      
      - name: Create data folder
        run: mkdir data
      
      - name: Build
        run: |
          cd src
          pyinstaller --onefile --windowed --name "LocalChat" --add-data "../models;models" --add-data "../data;data" --collect-all llama_cpp main.py
      
      - uses: actions/upload-artifact@v4
        with:
          name: LocalChat-Windows
          path: src/dist/*.exe